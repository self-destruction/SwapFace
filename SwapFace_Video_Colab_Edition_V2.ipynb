{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_B_zY0QOAEO"
      },
      "source": [
        "# üóø SwapFace Video Colab Extended Edition V2\n",
        "[![–û—Ç–∫—Ä—ã—Ç—å –≤ Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/self-destruction/SwapFace/blob/main/SwapFace_Video_Colab_Edition_V2.ipynb)\n",
        "\n",
        "##### –° –ø–æ–º–æ—â—å—é —ç—Ç–æ–≥–æ –±–ª–æ–∫–Ω–æ—Ç–∞ —Ç—ã –º–æ–∂–µ—à—å <b>–≤ –ø–∞—Ä—É –∫–ª–∏–∫–æ–≤</b> —Å–¥–µ–ª–∞—Ç—å –¥–∏–ø-—Ñ–µ–π–∫ –≤–∏–¥–µ–æ. –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–∞ YouTube-—Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ –∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –ª–∏—Ü–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –ª–∏—Ü–æ. –î–ª—è –∑–∞–º–µ–Ω—ã –ª–∏—Ü–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π [facefussion](https://github.com/facefusion/facefusion), –Ω–æ –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ –±–ª–æ–∫–Ω–æ—Ç Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "0CvYE0giOmRV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e723154611494e6980f04601d6fd1bf8",
            "6119cfe4b54f480ea3ab417d0fbc0c4c",
            "60fd9af341a34bffaba4375a0cfd192d"
          ]
        },
        "outputId": "130e39f3-232e-4dfb-ff67-bc903f008593"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='‚úî –ì–æ—Ç–æ–≤–æ', disabled=True, layout=Layout(min_width='300px'), style=‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e723154611494e6980f04601d6fd1bf8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title # –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—É–≥–ª –¥–∏—Å–∫–∞\n",
        "#@markdown ##### –ì—É–≥–ª-–¥–∏—Å–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –≤–∏–¥–µ–æ. –û–Ω –Ω–µ –∑–∞—Å–æ—Ä—è–µ—Ç—Å—è –Ω–∏—á–µ–º –¥—Ä—É–≥–∏–º.\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "from IPython.utils import capture\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "    print(\"[0;33m–ü–æ–¥–∫–ª—é—á–∞—é...\")\n",
        "    drive.mount('/content/drive')\n",
        "    mainpth=\"MyDrive\"\n",
        "clear_output()\n",
        "\n",
        "inf('\\u2714 –ì–æ—Ç–æ–≤–æ','success', '300px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CryN222Xk_rb"
      },
      "outputs": [],
      "source": [
        "# @title # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –ª–∏—Ü–æ\n",
        "#@markdown ##### –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–∏—Ü–∞ (.png, .jpg), –Ω–∞ –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–º–µ–Ω–∏—Ç—å –ª–∏—Ü–æ –≤ –∫–ª–∏–ø–µ\n",
        "#@markdown <font color=red>–ó–¥–µ—Å—å –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –ø—Ä–æ–≤–æ–¥–Ω–∏–∫:</font>\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "img_folder = '/content/input/source' #@param {type:\"string\"}\n",
        "!rm -rf {img_folder}\n",
        "!mkdir -p {img_folder}\n",
        "%cd {img_folder}\n",
        "SOURCE_FACE_IMAGE = ''\n",
        "TARGET_FACE_IMAGES = []\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for file_name in uploaded.keys():\n",
        "  SOURCE_FACE_IMAGE = os.path.join(img_folder, file_name)\n",
        "\n",
        "print(f\"{SOURCE_FACE_IMAGE}\")\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.axis('off')\n",
        "plt.imshow(Image.open(SOURCE_FACE_IMAGE))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TV6gYsFRlC99"
      },
      "outputs": [],
      "source": [
        "# @title #–£—Å—Ç–∞–Ω–æ–≤–∫–∞ facefussion\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "from pathlib import PosixPath\n",
        "import shutil\n",
        "\n",
        "ROOT_DIR = '/content'\n",
        "!mkdir -p {ROOT_DIR}/output\n",
        "\n",
        "%cd {ROOT_DIR}\n",
        "!git clone https://github.com/facefusion/facefusion -b next\n",
        "SWAPFACE_REPO_PATH = f'{ROOT_DIR}/facefusion'\n",
        "%cd {SWAPFACE_REPO_PATH}\n",
        "\n",
        "!pip install -q moviepy yt_dlp ffmpeg ffmpeg-python virtualenv\n",
        "!virtualenv venv\n",
        "!source {SWAPFACE_REPO_PATH}/venv/bin/activate; python install.py --torch cuda --onnxruntime cuda\n",
        "\n",
        "\n",
        "!sed -i 's/def analyse_frame(frame : Frame) -> bool:/def analyse_frame(frame : Frame) -> bool: True\\ndef analyse_frame123(frame : Frame) -> bool:/g' {SWAPFACE_REPO_PATH}/facefusion/content_analyser.py\n",
        "\n",
        "%cd {ROOT_DIR}\n",
        "print('–ì–æ—Ç–æ–≤–æ! –ü—Ä–æ–¥–æ–ª–∂–∞–π –¥–∞–ª—å—à–µ!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qx89vGzklU4W"
      },
      "outputs": [],
      "source": [
        "# @title # –°–∫–∞—á–∏–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "# @markdown #### –≠—Ç–æ—Ç —à–∞–≥ –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏ –≤—Ä—É—á–Ω—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ –≤ –ª—é–±—É—é –ø–∞–ø–∫—É.\n",
        "#@markdown ##### –í—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ Youtube:\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "import sys\n",
        "from moviepy.editor import VideoFileClip\n",
        "from pathlib import Path, PurePath\n",
        "from re import sub\n",
        "\n",
        "%cd {ROOT_DIR}\n",
        "url = 'https://www.youtube.com/watch?v=n6P0SitRwy8' #@param {type:\"string\"}\n",
        "\n",
        "input_download_path = f'{ROOT_DIR}/input/video'\n",
        "video_download_format = 'mp4'\n",
        "\n",
        "!rm -rf {input_download_path}\n",
        "!mkdir -p {input_download_path}\n",
        "\n",
        "video_opts = {\n",
        "  'format': f'bestvideo[height<=1080][ext={video_download_format}]+bestaudio[ext=m4a]/best[height<=1080]',\n",
        "  \"outtmpl\": f'{input_download_path}/%(title)s.%(ext)s',\n",
        "}\n",
        "\n",
        "def download_from_url(opts):\n",
        "  with yt_dlp.YoutubeDL(opts) as ydl:\n",
        "    ydl.download([url])\n",
        "\n",
        "download_from_url(video_opts)\n",
        "\n",
        "INPUT_VIDEO_FILE = str(next(Path(input_download_path).glob(f'*.{video_download_format}')))\n",
        "\n",
        "new_name = sub(r'[^\\w\\-_\\.]', '_', PurePath(INPUT_VIDEO_FILE).stem) + f'.{video_download_format}'\n",
        "new_path = str(Path(PurePath(INPUT_VIDEO_FILE).parent).joinpath(new_name))\n",
        "\n",
        "!mv \"{INPUT_VIDEO_FILE}\" \"{new_path}\"\n",
        "\n",
        "INPUT_VIDEO_FILE = new_path\n",
        "\n",
        "print(f\"–í–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ: {INPUT_VIDEO_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "fAFCYGWgEmRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49d121f-a34e-48d5-a48d-04b106c6da0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤–∏–¥–µ–æ –ø–æ –ø—É—Ç–∏: /content/input/video/Nirvana_-_Heart-Shaped_Box__Official_Music_Video_.mp4\n"
          ]
        }
      ],
      "source": [
        "# @title # –í—ã–±–∏—Ä–∞–µ–º –≤–∏–¥–µ–æ\n",
        "# @markdown ##### –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Ç—å –¥–æ –ø–∞–ø–∫–∏, —Ç—É–¥–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ –≤—Ä—É—á–Ω—É—é (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω mp4-—Ñ–∞–π–ª)\n",
        "# @markdown ##### –û—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∫–∞—á–µ–Ω–Ω–æ–µ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —à–∞–≥–µ –≤–∏–¥–µ–æ —Å YouTube\n",
        "# @markdown ---\n",
        "# @markdown ##### –ü—É—Ç—å –¥–æ –ø–∞–ø–∫–∏:\n",
        "from moviepy.editor import VideoFileClip\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from pathlib import Path\n",
        "from math import ceil\n",
        "import os\n",
        "\n",
        "input_video_folder = '' #@param {type:\"string\"}\n",
        "if input_video_folder != '':\n",
        "  INPUT_VIDEO_FILE = str(next(Path(input_video_folder).glob(f'*.mp4')))\n",
        "print(f\"–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤–∏–¥–µ–æ –ø–æ –ø—É—Ç–∏: {INPUT_VIDEO_FILE}\")\n",
        "\n",
        "input_download_path = f'{ROOT_DIR}/input/video'\n",
        "temp_input_dir = f'{input_download_path}/temp'\n",
        "\n",
        "!rm -rf {temp_input_dir}\n",
        "!mkdir -p {temp_input_dir}\n",
        "\n",
        "video = VideoFileClip(INPUT_VIDEO_FILE)\n",
        "\n",
        "# @markdown ##### –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä (–±–µ–∑ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —è—á–µ–π–∫–∞ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –º–æ–º–µ–Ω—Ç–∞–ª—å–Ω–æ):\n",
        "is_preview = False #@param {type:\"boolean\"}\n",
        "# @markdown ##### –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä, –ø–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω 30 —Å–µ–∫—É–Ω–¥–Ω—ã–π –∫—É—Å–æ–∫ (—è—á–µ–π–∫–∞ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ):\n",
        "is_only_one_clip = True #@param {type:\"boolean\"}\n",
        "piece_seconds = 30\n",
        "# –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 30-—Å–µ–∫—É–Ω–¥–Ω—ã—Ö –∫–ª–∏–ø–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –≤–∏–¥–µ–æ\n",
        "num_clips = 0 if is_preview != True else ceil(video.duration / piece_seconds) if is_only_one_clip != True else 1\n",
        "for i in range(num_clips):\n",
        "    start = i * piece_seconds\n",
        "    end = min((i + 1) * piece_seconds, video.duration)\n",
        "    clip = video.subclip(start, end).resize(height=420)\n",
        "    temp_clip_file = os.path.join(temp_input_dir, f\"clip_{i}.mp4\")\n",
        "    clip.write_videofile(temp_clip_file, logger=None, threads=64)\n",
        "    mp4 = open(temp_clip_file,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video id=\"my_video\" width=420 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    <script>\n",
        "    document.getElementById('my_video').volume = 0.2;\n",
        "    </script>\n",
        "    \"\"\" % data_url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGoMnyQjCyVQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "debug_mode = True\n",
        "\n",
        "#@title # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω\n",
        "# @markdown ### <font color=\"yellow\">–î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫—É</font>\n",
        "# @markdown ### –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞–¥—Ä –∏–∑ –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é —Å–ª–∞–π–¥–µ—Ä–∞ (–ª–µ–≤—ã–π –∫—Ä–∞–π - –Ω–∞—á–∞–ª–æ, –ø—Ä–∞–≤—ã–π –∫—Ä–∞–π - –∫–æ–Ω–µ—Ü):\n",
        "slider_value = 726838 # @param {type:\"slider\", min:1, max:1000000, step:1}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### <b>–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–ø-—Ñ–µ–π–∫–∞:</b>\n",
        "# @markdown ##### –£–ª—É—á—à–µ–Ω–∏–µ –ª–∏—Ü–∞ –ø–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã:\n",
        "face_enhancer_model = 'restoreformer' # @param [\"none\", \"codeformer\", \"gfpgan_1.2\", \"gfpgan_1.3\", \"gfpgan_1.4\", \"gpen_bfr_512\", \"restoreformer\"]\n",
        "face_enhancer_blend = 100 # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "face_enhancer_blend = str(face_enhancer_blend)\n",
        "# @markdown ##### –ú–æ–¥–µ–ª—å –∑–∞–º–µ–Ω—ã –ª–∏—Ü–∞ (<font color=\"grey\">inswapper_128</font> - –æ–±—ã—á–Ω–∞—è, <font color=\"grey\">inswapper_128_fp16</font> - –±—ã—Å—Ç—Ä–∞—è):\n",
        "face_swapper_model = 'inswapper_128_fp16' # @param [\"inswapper_128\", \"inswapper_128_fp16\", \"simswap_256\", \"simswap_512_unofficial\"]\n",
        "# @markdown ##### –£–ª—É—á—à–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞–¥—Ä–∞:\n",
        "frame_enhancer_model = 'none' # @param [\"none\", \"real_esrgan_x2plus\", \"real_esrgan_x4plus\", \"real_esrnet_x4plus\"]\n",
        "frame_enhancer_blend = 100 # @param {type:\"slider\", min:0, max:100, step:1}\n",
        "frame_enhancer_blend = str(frame_enhancer_blend)\n",
        "# @markdown ##### –¢–∏–ø –∑–∞–º–µ–Ω—ã (reference - –ª–∏—Ü–æ —Å —Ç–µ–∫—É—â–µ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞, many - –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Ü):\n",
        "face_selector_mode = 'reference' # @param [\"reference\", \"many\"]\n",
        "# @markdown ##### –£—Å–ª–æ–≤–∏—è –≤—ã–±–æ—Ä–∞ –ª–∏—Ü–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ç–∏–ø –∑–∞–º–µ–Ω—ã \"many\"):\n",
        "face_analyser_gender = 'none' # @param [\"none\", \"male\", \"female\"]\n",
        "if face_analyser_gender != 'none':\n",
        "  face_analyser_gender = f\"--face-analyser-gender {face_analyser_gender} \"\n",
        "else:\n",
        "  face_analyser_gender = ''\n",
        "face_analyser_age = 'none' # @param [\"none\", \"child\", \"teen\", \"adult\", \"senior\"]\n",
        "if face_analyser_age != 'none':\n",
        "  face_analyser_age = f\"--face-analyser-age {face_analyser_age} \"\n",
        "else:\n",
        "  face_analyser_age = ''\n",
        "face_detector_model = 'retinaface' # @param [\"retinaface\", \"yunet\"]\n",
        "\n",
        "temp_dir = '/content/input/temp'\n",
        "temp_file_name = 'temp.jpg'\n",
        "temp_file = os.path.join(temp_dir, temp_file_name)\n",
        "\n",
        "!rm -rf {temp_dir}\n",
        "!mkdir -p {temp_dir}\n",
        "\n",
        "%cd {SWAPFACE_REPO_PATH}\n",
        "\n",
        "# –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ\n",
        "clip = VideoFileClip(INPUT_VIDEO_FILE)\n",
        "frame_count = clip.fps * clip.duration\n",
        "frame = int((slider_value / 1000000) * frame_count)\n",
        "time_sec = frame / clip.fps\n",
        "print(f\"–ö–∞–¥—Ä {frame}, —Å–µ–∫—É–Ω–¥–∞ –≤–∏–¥–µ–æ {int(time_sec)}\")\n",
        "\n",
        "# –ø–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä –∏–∑ –≤–∏–¥–µ–æ\n",
        "cmd = (\n",
        " f\"import os, cv2;\"\n",
        " f\"cap = cv2.VideoCapture('{INPUT_VIDEO_FILE}', cv2.CAP_FFMPEG);\"\n",
        " f\"cap.set(cv2.CAP_PROP_POS_FRAMES, min({frame}, cap.get(cv2.CAP_PROP_FRAME_COUNT) - 1));\"\n",
        " f\"valid_frame, frame = cap.read();\"\n",
        " f\"cap.release();\"\n",
        " f\"frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if valid_frame else None;\"\n",
        " f\"print('frame is None') if frame is None else None;\"\n",
        " f\"frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if frame is not None else None;\"\n",
        " f\"print('Failed to save image') if not cv2.imwrite('{temp_file}', frame) else None;\"\n",
        ")\n",
        "\n",
        "!source {SWAPFACE_REPO_PATH}/venv/bin/activate; python -c \"{cmd}\"\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.axis('off')\n",
        "plt.imshow(Image.open(temp_file))\n",
        "plt.show()\n",
        "\n",
        "# ---\n",
        "\n",
        "OUTPUT_PATH = f'{ROOT_DIR}/output'\n",
        "output_name = 'temp_output'\n",
        "temp_ext = '.jpg'\n",
        "# _, temp_ext = os.path.splitext(SOURCE_FACE_IMAGE)\n",
        "temp_processed_file = os.path.join(OUTPUT_PATH, f\"{output_name}{temp_ext}\")\n",
        "\n",
        "!rm -rf {temp_processed_file}\n",
        "\n",
        "face_swapper_processor = 'face_swapper'\n",
        "face_enhancer_processor = 'face_enhancer'\n",
        "frame_enhancer_processor = 'frame_enhancer'\n",
        "\n",
        "frame_processors = face_swapper_processor\n",
        "\n",
        "if face_enhancer_model != 'none':\n",
        "    frame_processors = frame_processors + ' ' + face_enhancer_processor\n",
        "else:\n",
        "    face_enhancer_model = 'codeformer'\n",
        "if frame_enhancer_model != 'none':\n",
        "    frame_processors = frame_processors + ' ' + frame_enhancer_processor\n",
        "else:\n",
        "    frame_enhancer_model = 'real_esrgan_x2plus'\n",
        "\n",
        "cmd = (\n",
        "    f\"--source {Path(SOURCE_FACE_IMAGE)} \"\n",
        "    f\"--target {temp_file} \"\n",
        "    f\"--output {temp_processed_file} \"\n",
        "    f\"--headless \"\n",
        "    f\"--execution-providers cuda \"\n",
        "    f\"--execution-thread-count 128 \"\n",
        "    f\"--execution-queue-count 16 \"\n",
        "    f\"--max-memory 128 \"\n",
        "    f\"--face-analyser-order left-right \"\n",
        "    f\"{face_analyser_age}\"\n",
        "    f\"{face_analyser_gender}\"\n",
        "    f\"--face-detector-model {face_detector_model} \"\n",
        "    f\"--face-detector-size 640x640 \"\n",
        "    f\"--face-detector-score 0.5 \"\n",
        "    f\"--face-selector-mode {face_selector_mode} \"\n",
        "    f\"--reference-face-position 0 \"\n",
        "    f\"--reference-face-distance 1.5 \"\n",
        "    f\"--reference-frame-number {frame} \"\n",
        "    f\"--trim-frame-start 0 \"\n",
        "    f\"--trim-frame-end 0 \"\n",
        "    f\"--temp-frame-format jpg \"\n",
        "    f\"--temp-frame-quality 100 \"\n",
        "    f\"--output-image-quality 100 \"\n",
        "    f\"--output-video-encoder libx264 \"\n",
        "    f\"--output-video-quality 100 \"\n",
        "    f\"--keep-fps \"\n",
        "    f\"--output-image-quality 100 \"\n",
        "    f\"--frame-processors {frame_processors} \"\n",
        "    f\"--face-enhancer-model {face_enhancer_model} \"\n",
        "    f\"--face-enhancer-blend {face_enhancer_blend} \"\n",
        "    f\"--face-swapper-model {face_swapper_model} \"\n",
        "    f\"--frame-enhancer-model {frame_enhancer_model} \"\n",
        "    f\"--frame-enhancer-blend {frame_enhancer_blend} \"\n",
        "    f\"--ui-layouts default\"\n",
        ")\n",
        "\n",
        "if debug_mode == True:\n",
        "    print(cmd)\n",
        "\n",
        "!source {SWAPFACE_REPO_PATH}/venv/bin/activate; python run.py {cmd}\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.axis('off')\n",
        "plt.imshow(Image.open(temp_processed_file))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPPlPtEhle2Z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "from moviepy.editor import VideoFileClip\n",
        "from base64 import b64encode\n",
        "from math import ceil\n",
        "import os\n",
        "\n",
        "#@title # –ë–æ–µ–≤–æ–π –ø—Ä–æ–≥–æ–Ω\n",
        "# @markdown ### –î–µ–ª–∞–µ–º –¥–∏–ø—Ñ–µ–π–∫ –≤–∏–¥–µ–æ\n",
        "# @markdown *–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ—Ä—É—Ç—Å—è –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Ö –Ω–∞ —è—á–µ–π–∫–µ \"–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω\"*\n",
        "\n",
        "# @markdown ### –ü—Ä–æ–≥–Ω–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ N —Å–µ–∫—É–Ω–¥ (–Ω–∞—á–∏–Ω–∞—è —Å —Ä–∞–Ω–µ–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞)\n",
        "is_test_launch = False # @param {type:\"boolean\"}\n",
        "N = 3 # @param {type:\"slider\", min:1, max:30, step:1}\n",
        "\n",
        "%cd {SWAPFACE_REPO_PATH}\n",
        "\n",
        "GOOGLE_DRIVE_OUTPUT_FOLDER = f'{ROOT_DIR}/drive/MyDrive/SwapFace/output'\n",
        "OUTPUT_VIDEO_PATH = f'{ROOT_DIR}/output'\n",
        "output_video_name = os.path.splitext(os.path.basename(INPUT_VIDEO_FILE))[0]\n",
        "OUTPUT_VIDEO = os.path.join(GOOGLE_DRIVE_OUTPUT_FOLDER, f\"{output_video_name}.mp4\")\n",
        "video_input = INPUT_VIDEO_FILE\n",
        "temp_output_dir = f'{OUTPUT_PATH}/temp'\n",
        "\n",
        "!mkdir -p {GOOGLE_DRIVE_OUTPUT_FOLDER}\n",
        "!mkdir -p {OUTPUT_VIDEO_PATH}\n",
        "!rm -rf {temp_output_dir}\n",
        "!mkdir -p {temp_output_dir}\n",
        "\n",
        "cmd = (\n",
        "    f\"--source {Path(SOURCE_FACE_IMAGE)} \"\n",
        "    f\"--target {video_input} \"\n",
        "    f\"--output {OUTPUT_VIDEO} \"\n",
        "    f\"--headless \"\n",
        "    f\"--execution-providers cuda \"\n",
        "    f\"--execution-thread-count 64 \"\n",
        "    f\"--execution-queue-count 16 \"\n",
        "    f\"--max-memory 16 \"\n",
        "    f\"--face-recognition many \"\n",
        "    f\"--face-analyser-direction left-right \"\n",
        "    f\"--face-analyser-age adult \"\n",
        "    f\"--face-analyser-gender female \"\n",
        "    f\"--reference-face-position 0 \"\n",
        "    f\"--reference-face-distance 1.5 \"\n",
        "    f\"--reference-frame-number {frame} \"\n",
        "    # f\"--trim-frame-start 0 \"\n",
        "    # f\"--trim-frame-end 0 \"\n",
        "    f\"--temp-frame-format jpg \"\n",
        "    f\"--temp-frame-quality 80 \"\n",
        "    f\"--output-image-quality 100 \"\n",
        "    f\"--output-video-encoder libx264 \"\n",
        "    f\"--output-video-quality 100 \"\n",
        "    f\"--keep-fps \"\n",
        "    f\"--output-image-quality 100 \"\n",
        "    f\"--frame-processors {frame_processors} \"\n",
        "    f\"--face-enhancer-model {face_enhancer_model} \"\n",
        "    f\"--face-enhancer-blend {face_enhancer_blend} \"\n",
        "    f\"--face-swapper-model {face_swapper_model} \"\n",
        "    f\"--frame-enhancer-model {frame_enhancer_model} \"\n",
        "    f\"--frame-enhancer-blend {frame_enhancer_blend} \"\n",
        "    f\"--ui-layouts default\"\n",
        ")\n",
        "\n",
        "if is_test_launch == True:\n",
        "  temp_videofile_name = 'temp_video.mp4'\n",
        "  OUTPUT_VIDEO = os.path.join(GOOGLE_DRIVE_OUTPUT_FOLDER, temp_videofile_name)\n",
        "\n",
        "  clip = VideoFileClip(video_input)\n",
        "  start_time = frame / clip.fps\n",
        "  frame_finish = int(frame + N * clip.fps)\n",
        "  cmd = (\n",
        "      f\"--source {Path(SOURCE_FACE_IMAGE)} \"\n",
        "      f\"--target {video_input} \"\n",
        "      f\"--output {OUTPUT_VIDEO} \"\n",
        "      f\"--headless \"\n",
        "      f\"--execution-providers cuda \"\n",
        "      f\"--execution-thread-count 64 \"\n",
        "      f\"--execution-queue-count 16 \"\n",
        "      f\"--max-memory 16 \"\n",
        "      f\"--face-recognition many \"\n",
        "      f\"--face-analyser-direction left-right \"\n",
        "      f\"--face-analyser-age adult \"\n",
        "      f\"--face-analyser-gender female \"\n",
        "      f\"--reference-face-position 0 \"\n",
        "      f\"--reference-face-distance 1.5 \"\n",
        "      f\"--reference-frame-number {frame} \"\n",
        "      f\"--trim-frame-start {frame} \"\n",
        "      f\"--trim-frame-end {frame_finish} \"\n",
        "      f\"--temp-frame-format jpg \"\n",
        "      f\"--temp-frame-quality 80 \"\n",
        "      f\"--output-image-quality 100 \"\n",
        "      f\"--output-video-encoder libx264 \"\n",
        "      f\"--output-video-quality 100 \"\n",
        "      f\"--keep-fps \"\n",
        "      f\"--output-image-quality 100 \"\n",
        "      f\"--frame-processors {frame_processors} \"\n",
        "      f\"--face-enhancer-model {face_enhancer_model} \"\n",
        "      f\"--face-enhancer-blend {face_enhancer_blend} \"\n",
        "      f\"--face-swapper-model {face_swapper_model} \"\n",
        "      f\"--frame-enhancer-model {frame_enhancer_model} \"\n",
        "      f\"--frame-enhancer-blend {frame_enhancer_blend} \"\n",
        "      f\"--ui-layouts default\"\n",
        "  )\n",
        "\n",
        "if debug_mode == True:\n",
        "    !echo \"{cmd}\"\n",
        "\n",
        "!source {SWAPFACE_REPO_PATH}/venv/bin/activate; python run.py {cmd}\n",
        "\n",
        "NEW_OUTPUT_VIDEO = os.path.join(GOOGLE_DRIVE_OUTPUT_FOLDER, os.path.basename(OUTPUT_VIDEO))\n",
        "!mv {OUTPUT_VIDEO} {GOOGLE_DRIVE_OUTPUT_FOLDER}\n",
        "\n",
        "print(f\"–í–∏–¥–µ–æ –≥–æ—Ç–æ–≤–æ: {NEW_OUTPUT_VIDEO}\")\n",
        "\n",
        "video = VideoFileClip(NEW_OUTPUT_VIDEO)\n",
        "\n",
        "# @markdown ##### –í –ø—Ä–µ–≤—å—é –ø–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω 30 —Å–µ–∫—É–Ω–¥–Ω—ã–π –∫—É—Å–æ–∫ (—è—á–µ–π–∫–∞ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ):\n",
        "is_only_one_clip = True #@param {type:\"boolean\"}\n",
        "piece_seconds = 10\n",
        "# –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 30-—Å–µ–∫—É–Ω–¥–Ω—ã—Ö –∫–ª–∏–ø–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –≤–∏–¥–µ–æ\n",
        "num_clips = ceil(video.duration / piece_seconds) if is_only_one_clip != True else 1\n",
        "for i in range(num_clips):\n",
        "    start = i * piece_seconds\n",
        "    end = min((i + 1) * piece_seconds, video.duration)\n",
        "    clip = video.subclip(start, end).resize(height=420)\n",
        "    temp_clip_file = os.path.join(temp_output_dir, f\"clip_{i}.mp4\")\n",
        "    print(f\"–í—ã–≤–æ–∂—É –∫—É—Å–æ–∫ –Ω–∞ –ø—Ä–µ–≤—å—é: {temp_clip_file}\")\n",
        "    clip.write_videofile(temp_clip_file, logger=None, threads=32)\n",
        "    mp4 = open(temp_clip_file,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video id=\"my_video\" width=420 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    <script>\n",
        "    document.getElementById('my_video').volume = 0.2;\n",
        "    </script>\n",
        "    \"\"\" % data_url))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e723154611494e6980f04601d6fd1bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "‚úî –ì–æ—Ç–æ–≤–æ",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_6119cfe4b54f480ea3ab417d0fbc0c4c",
            "style": "IPY_MODEL_60fd9af341a34bffaba4375a0cfd192d",
            "tooltip": ""
          }
        },
        "6119cfe4b54f480ea3ab417d0fbc0c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "300px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60fd9af341a34bffaba4375a0cfd192d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
